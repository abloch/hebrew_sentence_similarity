# Henrew Sentences Similarity
This Framework enables, three type of model training, similarity evaluation, two test-sets validation with visualization and datasets embeding visualization for a given model.

## One-Time Setup
The data and models for this framework are stored at AWS S3 and are not part of this code. therefore. one needs to download them prior to working with the framework.
for this step you'll need an [AWS API token](https://docs.aws.amazon.com/STS/latest/APIReference/Welcome.html) (no worries, creating it is free)

`cd model;
./getter.sh; 
cd ../input ;
./getter.sh ;
cd ../output ;
./getter.sh`

## USAGE: 
`./sentence_similarity.py     < train | similarity | validation | visualize>   [other-options]`

## options:

## similarity:
`model-type=<w2v | fasttext | sent2vec>` which implementation of model should be used. default is w2v

`--input_file=<csv_file_full_path>`. The sentences should be arranged in a sentence in every line, see example in the input folder.

`--model-path=<model_file_full_path>`.
The trained model file that you want to work with.
You can download a pre-trained models for Word2Vec, FastText, Sent2Vec here

`--output_path=<file_full_path>`

`--verbosity=<number>`

`--similarity_type=<file_pairs| file_all| file_best_match| input>`. 
in case of `input`, two sentences need to be provided:

`sentence1="..."`. `sentence2="..."`

The output will be the similarity measurement for these two sentences
`file_pairs` - Will treat every two consecutives sentences in the `input_file` as pairs to compare.
For example if we have 
sentence_1
sentence_2
sentence_3
sentence_4

we the output will be a comparison between 
sentence_1 – sentence_2 
sentence_3 – sentence_4

`file_all` - Will compare all sentences with all sentences in the input file.
If we look at the example above, it will be
sentence_1 – sentence_2
sentence_1 – sentence_3
sentence_1 – sentence_4
sentence_2 – sentence_3 
sentence_4 – sentence_2   
sentence_3 – sentence_4

‘file_best_match’ – Will require `sentence1="..."` also as input.
The action will perform similarity comparison between input sentence1 and all the sentences in the input file and output a csv file with the sentences from the input file ranked by their similarity score

`--threshold` - When running with file_best_match or with ‘file_all’, a threshold can be set, that will allow only similarity results above this threshold to be returned

`--distance_type - <wm | cos>` - The distance function to be used for similarity measurement. cos is the default
the below options are required to be specified when training a new model:

##Train

`--train_path`- Train dataset full path

`model-type=<w2v | fasttext | sent2vec>` which implementation of model should be used. default is w2v

`--input_type - <yap | tweets>` - Input for training comes in YAP json format or general tweets format. See example in the input folder for each type

`--output_path=<file_full_path>`

| option          | description                                                                            | default |
|-----------------|----------------------------------------------------------------------------------------|---------|
| --batch_Size    | The batch size for training                                                            | 500     |
| --epochs_number | The number of epochs for training                                                      | 100     |
| --window        | The n-grams window for FastText and prediction for word2vec                            | 3       |
| --minimum_count | Ignores all words with total absolute frequency lower than this                        | 15      |
| --size          | Dimensionality of the feature vectors between 50-300                                   | 300     |
| --sample        | The threshold for configuration, which higher frequency words are randomly downsampled | 6e-5    |
| --alpha         | The initial learning rate                                                              | 0.03    |
| --workers       | The number of workers to use or -1 for using all cores                                 | -1      |


##Validation
the below options are required in order to validate a prediction against a given test set

`--predicted_path=<csv of similarities>` generated by similarity option.
See examples in the output folder

`--perfects_path=<csv of test set>` - The ground truth for the validation, it should have a the same sentence pairs order, as the input to predicted_path, with a column called similarity.
See example in the input folder, under test_set or validation_set folders.

`--number_classes` - Can be 2 or 4. 
This is the number of classes in perfects file.
The validation will run k-means into two groups or four groups.

`--visualize` -- Visualize the output as a confusion and scatter plot with the threshold for each class represented in the scatter plot


##Validation
Simple tool that allows to see the embedded vectors t-SNE distribution
See usage example bellow

##examples:

the simplest task is to measure the distance between two given sentences using a model:
```
./sentence_similarity.py similarity \
--similarity_type=input \
--model_type=fasttext \
--verbosity=1 \
--sentence1 'קרובים מאוד ליעד' \
--sentence2 'כמעט הגענו' \
--model_path=./models/fasttext/epochs_100__20190824-014157.bin \
--output_path=./out/ 
```

alternatively, one could use a csv file of pairs:
```
./sentence_similarity.py similarity \
--similarity_type=file_pairs \
--model_type=fasttext \
--verbosity=0 \
--input_file=./data/tweets_test.csv \
--model_path=./models/epochs_200__20190917-080634.bin \
--output_path=./out
```

one could specify a specific threshold of which amount of certainty is required to make a sentences similarity output:
```
./sentence_similarity.py similarity \
--similarity_type=file_all \
--model_type=w2v \
--verbosity=1 \
--input_file=./data/sentence_to_compare.csv \
--model_path=./models/epochs_30__20190823-201514.bin \
--output_path=./out\
--threshold=0.75
```

this tool could also be used to train a new models
```
./sentence_similarity.py train
--model_type=fasttext
--train_path=./data/tweets.json
--output_path=./models/fastText_trained_for_tweets_200_epochs_c15.bin
--input_type=tweets
--epochs_number=200
--verbosity=1
--minimum_count=15
```

here's how to validate a model against a given test set 
```
./sentence_similarity.py validation
--model_type=w2v
--predicted_path=./data/data_set.csv
--perfects_path=./data/test_set.csv
--output_path=./out
```

here's how to create a nice visualization of the three datasets
```
./sentence_similarity.py visualize
--model_type=fasttext
--train_dataset=./data/sentences.txt
--validation_dataset=./data/validation_set.csv
--test_dataset=./data/test_set.csv
--model_path=./models/epochs_100__20190824-014157.bin
--output_path=./out/image.png
```

